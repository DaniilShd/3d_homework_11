{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import open3d.ml.torch as ml3d\n",
    "import open3d.ml as o3dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n",
      "True\n",
      "1.26.4\n",
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(np.__version__)\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# poss_dataset.py\n",
    "import numpy as np\n",
    "import yaml\n",
    "import open3d.ml.torch as ml3d\n",
    "\n",
    "# POSS (17)\n",
    "POSS_LABELS = {\n",
    "    0: \"unlabeled\",\n",
    "    4: \"1 person\",\n",
    "    5: \"2+ person\",\n",
    "    6: \"rider\",\n",
    "    7: \"car\",\n",
    "    8: \"trunk\",\n",
    "    9: \"plants\",\n",
    "    10: \"traffic sign 1\", # standing sign\n",
    "    11: \"traffic sign 2\", # hanging sign\n",
    "    12: \"traffic sign 3\", # high/big hanging sign\n",
    "    13: \"pole\",\n",
    "    14: \"trashcan\",\n",
    "    15: \"building\",\n",
    "    16: \"cone/stone\",\n",
    "    17: \"fence\",\n",
    "    21: \"bike\",\n",
    "    22: \"ground\"} # class definition\n",
    "\n",
    "class POSSDataset(ml3d.datasets.SemanticKITTI):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        poss_yaml_path: str, # <--- poss.yaml\n",
    "        name: str = \"poss\",\n",
    "        cache_dir: str = \"./logs/cache_poss\",\n",
    "        use_cache: bool = False,\n",
    "        class_weights=None,\n",
    "        ignored_label_inds=None,\n",
    "        test_result_folder=None,\n",
    "        test_split=None,\n",
    "        training_split=None,\n",
    "        validation_split=None,\n",
    "        all_split=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(dataset_path=dataset_path,\n",
    "                         name=name,\n",
    "                         cache_dir=cache_dir,\n",
    "                         use_cache=use_cache,\n",
    "                         class_weights=class_weights,\n",
    "                         ignored_label_inds=ignored_label_inds or [],\n",
    "                         test_result_folder=test_result_folder,\n",
    "                         training_split=training_split or [\"00\",\"01\",\"02\",\"03\"],\n",
    "                         validation_split=validation_split or [\"04\"],\n",
    "                         test_split=test_split or [\"05\"],\n",
    "                         all_split=all_split or [\"00\",\"01\",\"02\",\"03\",\"04\",\"05\"],\n",
    "                         **kwargs)\n",
    "\n",
    "        self._poss_yaml_path = poss_yaml_path\n",
    "        with open(self._poss_yaml_path, \"r\") as f:\n",
    "            DATA = yaml.safe_load(f)\n",
    "\n",
    "        self.label_to_names = self.get_label_to_names()\n",
    "        self.num_classes = len(self.label_to_names)\n",
    "\n",
    "        # learning_map_inv: train_id -> raw_id\n",
    "        remap_dict_inv = DATA[\"learning_map_inv\"]\n",
    "        max_key = max(remap_dict_inv.keys()) if remap_dict_inv else 0\n",
    "        remap_lut = np.zeros((max_key + 100), dtype=np.int32)\n",
    "        remap_lut[list(remap_dict_inv.keys())] = list(remap_dict_inv.values())\n",
    "\n",
    "        # learning_map: raw_id -> train_id\n",
    "        remap_dict = DATA[\"learning_map\"]\n",
    "        max_key_val = max(remap_dict.keys()) if remap_dict else 0\n",
    "        remap_lut_val = np.zeros((max_key_val + 100), dtype=np.int32)\n",
    "        remap_lut_val[list(remap_dict.keys())] = list(remap_dict.values())\n",
    "\n",
    "        self.remap_lut = remap_lut\n",
    "        self.remap_lut_val = remap_lut_val\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_to_names():\n",
    "        return dict(POSS_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = POSSDataset(\n",
    "    dataset_path=\"./SemanticPOSS_dataset\",\n",
    "    poss_yaml_path=\"randlanet_poss.yml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points shape: (66658, 3)\n",
      "Labels shape: (66658,)\n"
     ]
    }
   ],
   "source": [
    "split = ds.get_split(\"train\")\n",
    "sample = split.get_data(0)\n",
    "points = sample[\"point\"].astype(np.float32)\n",
    "label = sample[\"label\"].astype(np.int32)\n",
    "\n",
    "print(f\"Points shape: {points.shape}\")\n",
    "print(f\"Labels shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ds.label_to_names\n",
    "num_classes = int(max(names.keys())) + 1\n",
    "rng = np.random.default_rng(0)\n",
    "palette = rng.random((num_classes, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_xyz = sample[\"point\"].astype(np.float32)   # (N, 4) - координаты + интенсивность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_infer = {\n",
    "    \"point\": points_xyz,      # Основной тензор точек для модели\n",
    "    \"full_point\": points_xyz  # ОБЯЗАТЕЛЬНОЕ ПОЛЕ для SemanticSegmentation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность points_xyz: (66534, 3)\n",
      "Количество признаков: 3\n"
     ]
    }
   ],
   "source": [
    "points_xyz = sample[\"point\"].astype(np.float32)\n",
    "print(f\"Размерность points_xyz: {points_xyz.shape}\")  # Должно быть (N, 4)\n",
    "print(f\"Количество признаков: {points_xyz.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тестовых данных (папка 04): (66534, 3)\n"
     ]
    }
   ],
   "source": [
    "# Проверьте размерность в тестовых данных\n",
    "test_split = ds.get_split(\"test\")\n",
    "sample = test_split.get_data(0)  # первый файл из папки 04\n",
    "points = sample[\"point\"].astype(np.float32)\n",
    "print(f\"Размерность тестовых данных (папка 04): {points.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels: 4\n",
      "num_classes: 15\n",
      "ignored_label_inds: [0]\n",
      "dataset_path: None\n",
      "test_split: None\n",
      "training_split: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"in_channels: {cfg.model.get('in_channels')}\")\n",
    "print(f\"num_classes: {cfg.model.get('num_classes')}\")\n",
    "print(f\"ignored_label_inds: {cfg.model.get('ignored_label_inds')}\")\n",
    "print(f\"dataset_path: {cfg.get('dataset_path')}\")\n",
    "print(f\"test_split: {cfg.get('test_split')}\")\n",
    "print(f\"training_split: {cfg.get('training_split')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Из за того что у меня стоит видеокарта нового поколения 5070 есть проблемы с совместью библиотек. Ниже начал обучение на cpu. По причине долгого обучения на cpu с вашего позволения не буду обучать модель до конца. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:218: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Wrong feature dimension, please update in_channels(3 + feature_dimension) in config",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_infer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Из за того что у меня стоит видеокарта нового поколения есть проблемы с совместью библиотек. Ниже начал обучение на cpu.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# По причине долгого обучения на cpu с вашего позволения не буду обучать до конца. \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/open3d/_ml3d/torch/pipelines/semantic_segmentation.py:166\u001b[39m, in \u001b[36mSemanticSegmentation.run_inference\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28mself\u001b[39m.ori_test_labels = []\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43munused_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minfer_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    634\u001b[39m         \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    635\u001b[39m         \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    674\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    677\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     49\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     49\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/open3d/_ml3d/torch/dataloaders/torch_dataloader.py:85\u001b[39m, in \u001b[36mTorchDataloader.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     82\u001b[39m     data = dataset.get_data(index)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m inputs = {\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m: data, \u001b[33m'\u001b[39m\u001b[33mattr\u001b[39m\u001b[33m'\u001b[39m: attr}\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/open3d/_ml3d/torch/models/randlanet.py:209\u001b[39m, in \u001b[36mRandLANet.transform\u001b[39m\u001b[34m(self, data, attr, min_possibility_idx)\u001b[39m\n\u001b[32m    206\u001b[39m     feat = np.concatenate([pc, feat], axis=\u001b[32m1\u001b[39m)\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cfg.in_channels != feat.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWrong feature dimension, please update in_channels(3 + feature_dimension) in config\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m     )\n\u001b[32m    213\u001b[39m input_points = []\n\u001b[32m    214\u001b[39m input_neighbors = []\n",
      "\u001b[31mRuntimeError\u001b[39m: Wrong feature dimension, please update in_channels(3 + feature_dimension) in config"
     ]
    }
   ],
   "source": [
    "res = pipeline.run_inference(data_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Загружаем конфигурацию\n",
    "cfg_file = 'randlanet_poss.yml'\n",
    "cfg = o3dml.utils.Config.load_from_file(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Получаем классы по именам из конфига\n",
    "DatasetClass = POSSDataset  # Используем наш кастомный класс\n",
    "ModelClass = o3dml.utils.get_module(\"model\", cfg.model.name, \"torch\")\n",
    "PipelineClass = o3dml.utils.get_module(\"pipeline\", cfg.pipeline.name, \"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем датасет POSS...\n"
     ]
    }
   ],
   "source": [
    "# 3. Создаем экземпляр датасета, используя параметры из конфига\n",
    "print(\"Загружаем датасет POSS...\")\n",
    "# Извлекаем путь к датасету и другие параметры\n",
    "dataset_path = cfg.dataset.pop('dataset_path', None)\n",
    "dataset = DatasetClass(dataset_path, \n",
    "                        \"randlanet_poss.yml\",\n",
    "                        **cfg.dataset)  # POSSDataset сам прочитает YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаем модель и pipeline...\n"
     ]
    }
   ],
   "source": [
    "# 4. Создаем модель и пайплайн\n",
    "print(\"Создаем модель и pipeline...\")\n",
    "model = ModelClass(**cfg.model)\n",
    "\n",
    "# Убедимся, что параметр 'dataset' (как строка) не передается в пайплайн\n",
    "pipeline_cfg = cfg.pipeline.copy()\n",
    "# Если он там есть, удаляем, т.к. передаем объект датасета явно\n",
    "pipeline_cfg.pop('dataset', None)\n",
    "\n",
    "pipeline = PipelineClass(\n",
    "    model=model,\n",
    "    dataset=dataset,  # Передаем объект датасета\n",
    "    device='cpu',    # или 'cpu'\n",
    "    **pipeline_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   2%|▏         | 19/994 [00:26<22:20,  1.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 5. Обучение модели\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mНачинаем обучение...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/open3d/_ml3d/torch/pipelines/semantic_segmentation.py:415\u001b[39m, in \u001b[36mSemanticSegmentation.run_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    413\u001b[39m     inputs[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m    414\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m loss, gt_labels, predict_scores = model.get_loss(\n\u001b[32m    417\u001b[39m     Loss, results, inputs, device)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predict_scores.size()[-\u001b[32m1\u001b[39m] == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/open3d/_ml3d/torch/models/randlanet.py:276\u001b[39m, in \u001b[36mRandLANet.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    274\u001b[39m encoder_feat_list = []\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg.num_layers):\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     feat_encoder_i = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mneighbor_indices_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     feat_sampled_i = \u001b[38;5;28mself\u001b[39m.random_sample(feat_encoder_i,\n\u001b[32m    279\u001b[39m                                         subsample_indices_list[i])\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/open3d/_ml3d/torch/models/randlanet.py:684\u001b[39m, in \u001b[36mLocalFeatureAggregation.forward\u001b[39m\u001b[34m(self, coords, feat, neighbor_indices)\u001b[39m\n\u001b[32m    681\u001b[39m x = \u001b[38;5;28mself\u001b[39m.mlp1(feat)\n\u001b[32m    683\u001b[39m x, neighbor_features = \u001b[38;5;28mself\u001b[39m.lse1(coords, x, neighbor_indices)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m x, _ = \u001b[38;5;28mself\u001b[39m.lse2(coords,\n\u001b[32m    687\u001b[39m                  x,\n\u001b[32m    688\u001b[39m                  neighbor_indices,\n\u001b[32m    689\u001b[39m                  relative_features=neighbor_features)\n\u001b[32m    690\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool2(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/daniil/d73a71ee-06a1-4243-882c-225fb09917a1/daniil/Learn/Semestr_3/3D/HomeWork/Homework_11/.venv/lib/python3.11/site-packages/open3d/_ml3d/torch/models/randlanet.py:636\u001b[39m, in \u001b[36mAttentivePooling.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    633\u001b[39m scores = \u001b[38;5;28mself\u001b[39m.score_fn(x.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m)).permute(\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    635\u001b[39m \u001b[38;5;66;03m# sum over the neighbors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m features = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (B, d_in, N, 1)\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mlp(features)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 5. Обучение модели\n",
    "print(\"Начинаем обучение...\")\n",
    "pipeline.run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Валидация\n",
    "print(\"\\nНачинаем валидацию...\")\n",
    "pipeline.run_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Тестирование и инференс (пример)\n",
    "print(\"\\nНачинаем тестирование...\")\n",
    "test_split = dataset.get_split(\"test\")\n",
    "if len(test_split) > 0:\n",
    "    sample = test_split.get_data(0)\n",
    "    data = {\n",
    "        \"point\": sample[\"point\"].astype(np.float32),\n",
    "        \"full_point\": sample[\"point\"].astype(np.float32)\n",
    "    }\n",
    "    print(\"Запуск инференса...\")\n",
    "    result = pipeline.run_inference(data)\n",
    "    print(f\"Размер предсказаний: {result['predict_labels'].shape}\")\n",
    "    print(f\"Уникальные классы в предсказаниях: {np.unique(result['predict_labels'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework-10-py3.11 (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
